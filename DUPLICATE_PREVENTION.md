# 重复文件预防方案

## ⚠️ 重要说明

使用 `--hash` 模式检测重复文件会：
- ✅ 准确检测所有重复文件
- ❌ **产生 OSS 外网下行流量费用**（约 0.5 元/GB）

对于 6365 个文件，如果平均每个文件 1 MB，总下载量约 6 GB，费用约 **3 元**。

## ✅ 已完成的修复（方案3）

### 修复内容

1. **`admin-dashboard.tsx`**
   - 创建资产时自动传递 hash 和 fileSize
   - 新上传的文件都会保存 hash 到 manifest.json

2. **`batch-upload-dialog.tsx`**
   - 批量上传时自动保存和传递 hash 和 fileSize
   - 批量上传的文件也会保存 hash

### 效果

**从现在开始，所有新上传的文件都会：**
- ✅ 自动计算 hash
- ✅ 保存 hash 到 manifest.json
- ✅ 上传前自动检测重复（基于 hash）
- ✅ 如果重复，会复用已有文件，不会重复上传

## 🔍 检测重复文件的方案

### 方案 1：使用 manifest.json（推荐，免费）

**适用场景：** 新上传的文件（已有 hash）

```bash
npm run cleanup-duplicates
```

**优点：**
- ✅ 完全免费（不下载文件）
- ✅ 速度快
- ✅ 准确（基于文件内容 hash）

**缺点：**
- ❌ 只能检测 manifest.json 中有 hash 的文件
- ❌ 历史文件如果没有 hash，无法检测

### 方案 2：使用文件名+大小（免费但不准确）

```bash
npx tsx scripts/cleanup-duplicate-files.ts --no-manifest
```

**优点：**
- ✅ 完全免费
- ✅ 速度快

**缺点：**
- ❌ 只能检测文件名相同且大小相同的文件
- ❌ 文件名不同但内容相同的文件检测不到

### 方案 3：下载文件计算 hash（准确但收费）

```bash
npx tsx scripts/cleanup-duplicate-files.ts --hash
```

**优点：**
- ✅ 最准确，能检测所有重复文件

**缺点：**
- ❌ 产生 OSS 下行流量费用
- ❌ 速度慢

## 📊 当前情况

### 历史文件

- **问题**：历史文件可能没有 hash 信息
- **影响**：无法使用 manifest.json 模式检测
- **解决方案**：
  1. 等待新文件积累 hash（推荐）
  2. 或手动检查相同大小的文件组

### 新上传的文件

- **状态**：✅ 已修复，会自动保存 hash
- **效果**：上传前自动检测重复，不会重复上传
- **检测**：可以使用 manifest.json 模式免费检测

## 🎯 推荐策略

### 短期（现在）

1. **停止 hash 下载检测**（避免费用）
2. **使用文件名+大小检测**（免费，快速）
   ```bash
   npm run find-same-size
   ```
3. **手动检查**相同大小的文件组，判断是否真的重复

### 中期（1-2 周后）

1. **新上传的文件已积累 hash**
2. **使用 manifest.json 模式检测**（免费）
   ```bash
   npm run cleanup-duplicates
   ```
3. 清理新文件中的重复

### 长期

1. **所有新文件都有 hash**
2. **上传时自动检测重复**
3. **定期使用 manifest.json 模式清理**（免费）

## 💡 建议

1. **优先使用 manifest.json 模式**（免费且准确）
2. **等待新文件积累 hash**（1-2 周）
3. **避免使用 --hash 模式**（除非必要且愿意付费）
4. **定期清理**（每月一次，使用 manifest.json 模式）

## 📝 总结

- ✅ **已修复上传流程**：新文件会自动保存 hash
- ✅ **上传时自动检测重复**：不会重复上传
- ✅ **免费检测方案**：使用 manifest.json 模式
- ⚠️ **避免费用**：不使用 --hash 模式下载文件

